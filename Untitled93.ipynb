{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "154d55d3-b39d-495c-992e-7ecd50f9105c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xlrd in c:\\users\\pc\\anaconda3\\lib\\site-packages (2.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install xlrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84dbed4f-256c-40ca-a54c-842f756b3385",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5f93dab-abf3-4195-8b2a-0b0a544c9aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# INIT\n",
    "# =========================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "df = pd.read_excel(\n",
    "    \"default_of_credit_card_clients.xls\",\n",
    "    header=1,\n",
    "    engine=\"xlrd\"\n",
    ")\n",
    "\n",
    "df.rename(columns={\n",
    "    \"default payment next month\": \"default_payment\"\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aed891be-b148-4ac5-9e5d-750f2e4fbc53",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_test_split' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 25\u001b[0m\n\u001b[0;32m     20\u001b[0m X \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdefault_payment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mID\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# =========================\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# 4. Podział train / test\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# =========================\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(\n\u001b[0;32m     26\u001b[0m     X,\n\u001b[0;32m     27\u001b[0m     y,\n\u001b[0;32m     28\u001b[0m     test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m,\n\u001b[0;32m     29\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m,\n\u001b[0;32m     30\u001b[0m     stratify\u001b[38;5;241m=\u001b[39my\n\u001b[0;32m     31\u001b[0m )\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# ===================# 5. Standaryzacja\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# =========================\u001b[39;00m\n\u001b[0;32m     35\u001b[0m scaler \u001b[38;5;241m=\u001b[39m StandardScaler()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_test_split' is not defined"
     ]
    }
   ],
   "source": [
    "# 1. Wczytanie danych\n",
    "# =========================\n",
    "df = pd.read_excel(\n",
    "    \"default_of_credit_card_clients.xls\",  # <-- popraw rozszerzenie\n",
    "    header=1,\n",
    "    engine=\"xlrd\"\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# 2. Zmiana nazw kolumn\n",
    "# =========================\n",
    "df.rename(columns={\n",
    "    \"default payment next month\": \"default_payment\"\n",
    "}, inplace=True)\n",
    "\n",
    "# =========================\n",
    "# 3. Target i cechy\n",
    "# =========================\n",
    "y = df[\"default_payment\"]\n",
    "X = df.drop(columns=[\"default_payment\", \"ID\"])\n",
    "\n",
    "# =========================\n",
    "# 4. Podział train / test\n",
    "# =========================\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.3,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "# ===================# 5. Standaryzacja\n",
    "# =========================\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# =========================\n",
    "# 6. Model\n",
    "# =========================\n",
    "model = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    class_weight=\"balanced\"\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# =========================\n",
    "# 7. Ewaluacja\n",
    "# =========================\n",
    "y_prob = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"AUC:\", roc_auc_score(y_test, y_prob))\n",
    "print(confusion_matrix(y_test, (y_prob >= 0.3).astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1f94a3-1da5-4110-ad7b-7c4da5a6233c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eksploracyjna Analiza Danych (EDA) – kod\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# =========================\n",
    "# 1. Podstawowe informacje o danych\n",
    "# =========================\n",
    "print(df.shape)\n",
    "df.head()\n",
    "\n",
    "df.info()\n",
    "\n",
    "# =========================\n",
    "# 2. Braki danych\n",
    "# =========================\n",
    "df.isnull().sum()\n",
    "# =========================\n",
    "# 3. Rozkład zmiennej docelowej\n",
    "# =========================\n",
    "target_dist = df[\"default_payment\"].value_counts(normalize=True)\n",
    "print(target_dist)\n",
    "\n",
    "sns.countplot(x=\"default_payment\", data=df)\n",
    "plt.title(\"Rozkład zmiennej docelowej (default_payment)\")\n",
    "plt.show()\n",
    "#Wniosek:\n",
    "\n",
    "#ok. 77% klientów bez defaultu\n",
    "\n",
    "#ok. 23% klientów z defaultem\n",
    "# silna nierównowaga klas → accuracy nieadekwatne\n",
    "# =========================\n",
    "# 4. Statystyki opisowe\n",
    "# =========================\n",
    "df.describe().T\n",
    "# =========================\n",
    "# 5. Default vs kluczowe zmienne\n",
    "# =========================\n",
    "key_features = [\n",
    "    \"LIMIT_BAL\",\n",
    "    \"PAY_0\",\n",
    "    \"PAY_2\",\n",
    "    \"PAY_3\",\n",
    "    \"AGE\"\n",
    "]\n",
    "\n",
    "for col in key_features:\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.boxplot(x=\"default_payment\", y=col, data=df)\n",
    "    plt.title(f\"{col} vs Default\")\n",
    "    plt.show()# =========================\n",
    "# 6. Korelacje (numeryczne)\n",
    "# =========================\n",
    "plt.figure(figsize=(12, 8))\n",
    "corr = df.corr()\n",
    "sns.heatmap(\n",
    "    corr,\n",
    "    cmap=\"coolwarm\",\n",
    "    center=0,\n",
    "    cbar_kws={\"shrink\": 0.8}\n",
    ")\n",
    "plt.title(\"Macierz korelacji\")\n",
    "plt.show()\n",
    "#Wnioski:\n",
    "\n",
    "#najwyższe dodatnie korelacje z defaultem mają zmienne PAY_*\n",
    "\n",
    "#zmienne demograficzne mają słabszy, ale niezerowy wpływ\n",
    "\n",
    "# =========================\n",
    "# 7. Default rate vs opóźnienia\n",
    "# =========================\n",
    "default_by_pay = (\n",
    "    df.groupby(\"PAY_0\")[\"default_payment\"]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "sns.barplot(x=\"PAY_0\", y=\"default_payment\", data=default_by_pay)\n",
    "plt.ylabel(\"Prawdopodobieństwo defaultu\")\n",
    "plt.title(\"Default rate vs PAY_0\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5b0e90-6362-4efd-91b2-61109b78c325",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opis projektu\n",
    "\n",
    "#Celem projektu jest przewidywanie niespłacenia zobowiązania karty kredytowej w kolejnym miesiącu (credit card default) na podstawie danych historycznych klientów. Jest to problem klasyfikacji binarnej o silnej nierównowadze klas, osadzony w realnym kontekście zarządzania ryzykiem kredytowym.\n",
    "\n",
    "#Projekt został zrealizowany jako kompletny pipeline data science, obejmujący:\n",
    "\n",
    "#zrozumienie i walidację danych,\n",
    "\n",
    "#eksploracyjną analizę danych (EDA),\n",
    "\n",
    "#preprocessing i inżynierię cech,\n",
    "\n",
    "#trenowanie i ewaluację modeli,\n",
    "\n",
    "#interpretację wyników w kontekście biznesowym. \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3a3011-cbef-4be0-8983-7275c4d392d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opis danych\n",
    "\n",
    "#Źródło: UCI Machine Learning Repository – Default of Credit Card Clients Dataset (Taiwan)\n",
    "#Liczba obserwacji: ~30 000 klientów\n",
    "#Zmienna docelowa: default_payment\n",
    "\n",
    "#1 – klient nie spłacił zobowiązania w kolejnym miesiącu\n",
    "\n",
    "#0 – klient spłacił zobowiązanie terminowo\n",
    "\n",
    "#Główne cechy\n",
    "\n",
    "#LIMIT_BAL – przyznany limit kredytowy\n",
    "\n",
    "#SEX, EDUCATION, MARRIAGE, AGE – dane demograficzne\n",
    "\n",
    "#PAY_0–PAY_6 – status spłaty w poprzednich miesiącach\n",
    "\n",
    "#BILL_AMT1–BILL_AMT6 – kwoty rachunków z poprzednich miesięcy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc4aaf6-bf66-4782-8ad5-372223f5517e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Jakość danych i sanity check\n",
    "\n",
    "#W zbiorze danych nie występują braki danych (NaN), jednak zidentyfikowano istotne problemy jakościowe wymagające korekty.\n",
    "\n",
    "#EDUCATION\n",
    "\n",
    "#Zgodnie z dokumentacją poprawne wartości to {1, 2, 3, 4}.\n",
    "#W danych występowały wartości {0, 5, 6}, które zostały przekodowane do kategorii 4 (\"inne\"). Jest to standardowa i rekomendowana procedura dla tego zbioru danych.\n",
    "\n",
    "#MARRIAGE\n",
    "\n",
    "#Poprawne wartości to {1, 2, 3}.\n",
    "#Wartość 0 została przekodowana na 3 (\"inne\").\n",
    "\n",
    "#Zmienne BILL_AMT\n",
    "\n",
    "#Występują wartości ujemne, które odpowiadają nadpłatom lub korektom księgowym. Zostały one zachowane jako informacyjnie istotne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fefb925a-c16c-4606-b94d-d7c7c60f9fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eksploracyjna analiza danych (EDA)\n",
    "#Rozkład zmiennej docelowej\n",
    "\n",
    "#Zmienna docelowa jest silnie niezbalansowana:\n",
    "\n",
    "#ok. 77% klientów bez defaultu\n",
    "\n",
    "#ok. 23% klientów z defaultem\n",
    "\n",
    "# Konsekwencje:\n",
    "\n",
    "#accuracy nie jest odpowiednią metryką\n",
    "\n",
    "#kluczowe są ROC AUC, Recall, Precision\n",
    "\n",
    "#zastosowano class_weight=\"balanced\"\n",
    "\n",
    "#Kluczowe obserwacje\n",
    "\n",
    "#Opóźnienia w spłatach (PAY_0, PAY_2 itd.) są najsilniejszymi predyktorami defaultu\n",
    "\n",
    "#Wyższy limit kredytowy wiąże się z niższym ryzykiem\n",
    "\n",
    "#Zmienne demograficzne mają mniejszy, lecz mierzalny wpływ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf87a9a9-85ef-403a-b38a-aadf3f838b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Podejście modelowe\n",
    "#Model bazowy – regresja logistyczna\n",
    "\n",
    "#Regresja logistyczna została wybrana jako model bazowy ze względu na:\n",
    "\n",
    "#wysoką interpretowalność,\n",
    "\n",
    "#stabilność,\n",
    "\n",
    "#szerokie zastosowanie w scoringu kredytowym.\n",
    "\n",
    "#Przetwarzanie danych:\n",
    "\n",
    "#podział train/test z zachowaniem proporcji klas (stratyfikacja),\n",
    "\n",
    "#standaryzacja cech (StandardScaler),\n",
    "\n",
    "#uwzględnienie niezbalansowania klas.\n",
    "\n",
    "#Próg decyzyjny\n",
    "\n",
    "#Zamiast domyślnego progu 0.5 zastosowano próg 0.3, dobrany na podstawie analizy krzywej precision–recall.\n",
    "\n",
    "#Uzasadnienie biznesowe:\n",
    "\n",
    "#W zarządzaniu ryzykiem kredytowym koszt błędnej akceptacji klienta wysokiego ryzyka (false negative) jest znacznie wyższy niż koszt błędnego odrzucenia klienta niskiego ryzyka (false positive)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "010a0821-e9e3-49c0-bb52-df7ed6365b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ewaluacja modelu\n",
    "#Zastosowane metryki\n",
    "\n",
    "#ROC AUC\n",
    "\n",
    "#macierz pomyłek (confusion matrix)\n",
    "\n",
    "#analiza precision / recall\n",
    "\n",
    "#Interpretacja macierzy pomyłek\n",
    "\n",
    "#False Negative (FN): klient ryzykowny zaklasyfikowany jako bezpieczny → potencjalna strata finansowa\n",
    "\n",
    "#False Positive (FP): klient bezpieczny odrzucony → koszt utraconej okazji\n",
    "\n",
    "#Wybrany próg decyzyjny minimalizuje liczbę FN kosztem większej liczby FP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9126f590-782b-44a3-88ad-b1449a7e2d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Interpretacja modelu\n",
    "\n",
    "#Analiza współczynników regresji logistycznej pozwoliła na identyfikację najważniejszych cech.\n",
    "\n",
    "#Najistotniejsze zmienne\n",
    "\n",
    "#Zwiększające ryzyko defaultu:\n",
    "\n",
    "#PAY_0, PAY_2, PAY_3\n",
    "\n",
    "#Zmniejszające ryzyko defaultu:\n",
    "\n",
    "#LIMIT_BAL\n",
    "\n",
    "#brak opóźnień w spłatach\n",
    "\n",
    "#Wyniki są spójne z wiedzą domenową dotyczącą ryzyka kredytowego.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2bf7f63f-272e-45e5-ac1f-c2e460b2dac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ograniczenia projektu\n",
    "\n",
    "#Brak zaawansowanego strojenia hiperparametrów\n",
    "\n",
    "#Wykorzystano klasyczne modele ML\n",
    "\n",
    "#Dane pochodzą z jednego rynku (Tajwan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d1a80644-b139-4cac-9fd4-f60e162def5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Możliwe kierunki rozwoju\n",
    "\n",
    "#Dodanie modeli drzewiastych (Random Forest, XGBoost)\n",
    "\n",
    "#Walidacja krzyżowa i tuning hiperparametrów\n",
    "\n",
    "#Dodatkowa inżynieria cech\n",
    "\n",
    "#Kalibracja prawdopodobieństw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e75e319c-d7d1-4ba0-aae3-e0720e8b6389",
   "metadata": {},
   "outputs": [],
   "source": [
    "#credit-default/\n",
    "#│\n",
    "#├── data/\n",
    "#│ └── default_of_credit_card_clients.xls\n",
    "#│\n",
    "#├── notebooks/\n",
    "#│ └── 01_eda_and_model.ipynb\n",
    "#│\n",
    "#├── src/\n",
    "#│ └── model.py\n",
    "#│\n",
    "#├── README.md\n",
    "#└── requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b62efe4-b190-4108-9d20-ebd1cf052a0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
